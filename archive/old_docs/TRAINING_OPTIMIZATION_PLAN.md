# üéØ Training Optimization Plan - Realistic & Demo-Ready

## üìä Ph√¢n t√≠ch Dataset Size

### Dataset hi·ªán c√≥:

| Dataset | Rows | Features | Size | Training Time (est.) |
|---------|------|----------|------|---------------------|
| **Network** | 211,044 | 44 | 29 MB | ~15-20 min |
| **Linux Process** | 90,113 | 16 | Large | ~10 min |
| **Linux Disk** | 90,113 | 8 | Large | ~8 min |
| **Linux Memory** | 70,113 | 12 | Large | ~8 min |
| **IoT Fridge** | 39,945 | 6 | Small | ~3 min |
| **IoT Garage** | 39,588 | 6 | Small | ~3 min |
| **IoT Motion** | 39,489 | 6 | Small | ~3 min |
| **IoT Weather** | 39,261 | 7 | Small | ~3 min |
| **IoT GPS** | 38,961 | 6 | Small | ~3 min |
| **IoT Thermostat** | 32,775 | 6 | Small | ~2 min |
| **IoT Modbus** | 31,107 | 8 | Small | ~3 min |
| **Windows 10** | 21,105 | 126 | Large | ~8 min |
| **Windows 7** | 15,981 | 134 | Large | ~7 min |
| **TOTAL** | **759,595** | **385+** | - | **~76 minutes** |

---

## ‚ö†Ô∏è V·∫§N ƒê·ªÄ:

1. **Qu√° nhi·ªÅu data** - 759K rows, train h·∫øt 76 ph√∫t qu√° l√¢u
2. **D∆∞ th·ª´a IoT devices** - 7 lo·∫°i IoT device, nhi·ªÅu overlap
3. **Linux c√≥ 3 datasets** - C√≥ th·ªÉ g·ªôp ho·∫∑c ch·ªçn 1
4. **Windows 2 versions** - Win7 + Win10 t∆∞∆°ng t·ª± nhau

---

## ‚úÖ GI·∫¢I PH√ÅP: Training Strategy cho Demo

### Strategy 1: **MINIMAL (Recommended for Demo)** ‚≠ê
**M·ª•c ti√™u:** Demo nhanh, ƒë·ªß 4 layers, training < 15 ph√∫t

#### Ch·ªçn datasets:

| Layer | Dataset ch·ªçn | Rows | L√Ω do |
|-------|-------------|------|-------|
| 1. Network | train_test_network.csv (sampled 50K) | 50,000 | ƒê·ªß ƒëa d·∫°ng attacks |
| 2. IoT | **Modbus ONLY** | 31,107 | Industrial ICS, quan tr·ªçng nh·∫•t |
| 3. Linux | Linux Process ONLY | 90,113 ‚Üí 30K | CPU/process l√† critical |
| 4. Windows | Windows 10 ONLY | 21,105 | Win10 ph·ªï bi·∫øn h∆°n Win7 |

**Training time:** ~15-20 minutes
**Total data:** ~132K rows
**Storage:** ~5 MB models

---

### Strategy 2: **BALANCED (Recommended for Production)**
**M·ª•c ti√™u:** C√¢n b·∫±ng gi·ªØa performance v√† th·ªùi gian

#### Ch·ªçn datasets:

| Layer | Dataset ch·ªçn | Rows | L√Ω do |
|-------|-------------|------|-------|
| 1. Network | Full dataset | 211,044 | Layer quan tr·ªçng nh·∫•t |
| 2. IoT | Modbus + Fridge + Thermostat | ~103K | 3 device types ƒë·∫°i di·ªán |
| 3. Linux | Process + Disk (combined) | ~180K ‚Üí 60K | Full system view |
| 4. Windows | Windows 10 only | 21,105 | Modern OS |

**Training time:** ~35-40 minutes
**Total data:** ~395K rows
**Storage:** ~8 MB models

---

### Strategy 3: **FULL (Not Recommended)**
**M·ª•c ti√™u:** Train h·∫øt (nh∆∞ guide g·ªëc)

**Training time:** ~76 minutes
**Total data:** 759K rows
**Kh√¥ng c·∫ßn thi·∫øt cho demo!**

---

## üéØ RECOMMENDED: Strategy 1 - MINIMAL

### L√Ω do ch·ªçn:

1. **‚úÖ ƒê·ªß 4 layers** - Demo ƒë·∫ßy ƒë·ªß architecture
2. **‚úÖ Nhanh** - 15-20 ph√∫t training
3. **‚úÖ ƒê·∫°i di·ªán** - M·ªói layer c√≥ dataset ƒëi·ªÉn h√¨nh
4. **‚úÖ Kh·∫£ thi** - D·ªÖ debug, d·ªÖ test
5. **‚úÖ Demo-ready** - ƒê·ªß ƒë·ªÉ showcase zero-day detection

### Datasets c·ª• th·ªÉ:

```
src/
  train_minimal.py          ‚Üê Script train minimal

models/minimal/
  network_autoencoder.h5    ‚Üê 50K network samples
  iot_modbus_autoencoder.h5 ‚Üê 31K Modbus samples
  linux_autoencoder.h5      ‚Üê 30K process samples
  windows_autoencoder.h5    ‚Üê 21K Win10 samples
```

---

## üíª Implementation: train_minimal.py

**File:** `src/train_minimal.py`

```python
"""
Minimal Training Script for Demo
Trains 4 layers with reduced datasets for quick demo
"""

import os
import sys
import numpy as np
import pandas as pd
import joblib
from tensorflow import keras

# Import modules
from data_loader import load_ton_iot_data
from preprocessor import preprocess_data, normalize_data
from model_builder import build_autoencoder, train_autoencoder
from threshold_finder import calculate_reconstruction_error

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


def sample_data(X, y, n_samples=50000, random_state=42):
    """Sample subset of data"""
    if len(X) <= n_samples:
        return X, y

    from sklearn.utils import resample
    X_sampled, y_sampled = resample(X, y, n_samples=n_samples, random_state=random_state, stratify=y)
    return X_sampled, y_sampled


def train_network_minimal():
    """Train network layer with 50K samples"""
    print("\n" + "="*60)
    print("LAYER 1: NETWORK (50K samples)")
    print("="*60)

    # Load full dataset
    df = load_ton_iot_data('../data/Train_Test_datasets/Train_Test_Network_dataset/train_test_network.csv')

    # Preprocess
    X, y_attack, y_zero_day, y_labels = preprocess_data(
        df,
        label_col='type',
        zero_day_attacks=['ransomware', 'mitm', 'injection', 'xss']
    )

    # Sample 50K
    print(f"[INFO] Sampling from {len(X)} to 50,000 samples...")
    X_sampled, y_sampled = sample_data(X.values, y_attack.values, n_samples=50000)

    # Split
    X_train, X_temp, y_train, y_temp = train_test_split(X_sampled, y_sampled, test_size=0.3, random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

    # Normalize
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)

    # Build model (smaller architecture for speed)
    input_dim = X_train_scaled.shape[1]
    model = build_autoencoder(input_dim, encoding_dims=[32, 16])  # Smaller than [128, 64, 32]

    # Train (fewer epochs)
    history = train_autoencoder(model, X_train_scaled, X_val_scaled, epochs=30, batch_size=256)

    # Find threshold
    train_errors = calculate_reconstruction_error(model, X_train_scaled)
    threshold = np.percentile(train_errors, 95)

    # Save
    os.makedirs('../models/minimal', exist_ok=True)
    model.save('../models/minimal/network_autoencoder.h5')
    joblib.dump(scaler, '../models/minimal/network_scaler.pkl')
    joblib.dump(threshold, '../models/minimal/network_threshold.pkl')

    print(f"[DONE] Network layer trained. Threshold: {threshold:.6f}")
    return model, scaler, threshold


def train_iot_minimal():
    """Train IoT layer - Modbus ONLY"""
    print("\n" + "="*60)
    print("LAYER 2: IoT MODBUS (31K samples)")
    print("="*60)

    # Load Modbus dataset
    df = pd.read_csv('../data/Train_Test_datasets/Train_Test_IoT_dataset/Train_Test_IoT_Modbus.csv')

    print(f"[INFO] Dataset shape: {df.shape}")

    # Preprocess
    drop_cols = ['date', 'time', 'label', 'type']
    X = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')
    y = df['label'].values if 'label' in df.columns else np.zeros(len(df))

    # Convert to numeric
    from sklearn.preprocessing import LabelEncoder
    for col in X.select_dtypes(include=['object']).columns:
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col].astype(str))

    X = X.apply(pd.to_numeric, errors='coerce').fillna(0).values

    # Split
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

    # Normalize
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)

    # Build model (simple for small feature set)
    input_dim = X_train_scaled.shape[1]
    model = keras.Sequential([
        keras.layers.Input(shape=(input_dim,)),
        keras.layers.Dense(8, activation='relu'),
        keras.layers.Dense(4, activation='relu'),
        keras.layers.Dense(8, activation='relu'),
        keras.layers.Dense(input_dim, activation='linear')
    ])
    model.compile(optimizer='adam', loss='mse')

    # Train
    model.fit(
        X_train_scaled, X_train_scaled,
        epochs=20,
        batch_size=128,
        validation_data=(X_val_scaled, X_val_scaled),
        verbose=1,
        callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]
    )

    # Find threshold
    train_pred = model.predict(X_train_scaled, verbose=0)
    train_errors = np.mean(np.power(X_train_scaled - train_pred, 2), axis=1)
    threshold = np.percentile(train_errors, 95)

    # Save
    model.save('../models/minimal/iot_modbus_autoencoder.h5')
    joblib.dump(scaler, '../models/minimal/iot_modbus_scaler.pkl')
    joblib.dump(threshold, '../models/minimal/iot_modbus_threshold.pkl')

    print(f"[DONE] IoT Modbus layer trained. Threshold: {threshold:.6f}")
    return model, scaler, threshold


def train_linux_minimal():
    """Train Linux layer - Process ONLY (sampled 30K)"""
    print("\n" + "="*60)
    print("LAYER 3: LINUX PROCESS (30K samples)")
    print("="*60)

    # Load process dataset
    df = pd.read_csv('../data/Train_Test_datasets/Train_Test_Linux_dataset/Train_Test_Linux_process.csv')

    print(f"[INFO] Original dataset shape: {df.shape}")

    # Preprocess
    drop_cols = ['CMD', 'attack', 'type', 'label']
    X = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')
    y = df['attack'].values if 'attack' in df.columns else np.zeros(len(df))

    X = X.apply(pd.to_numeric, errors='coerce').fillna(0).values

    # Sample 30K
    print(f"[INFO] Sampling from {len(X)} to 30,000 samples...")
    X_sampled, y_sampled = sample_data(X, y, n_samples=30000)

    # Split
    X_train, X_temp, y_train, y_temp = train_test_split(X_sampled, y_sampled, test_size=0.3, random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

    # Normalize
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)

    # Build model
    input_dim = X_train_scaled.shape[1]
    model = keras.Sequential([
        keras.layers.Input(shape=(input_dim,)),
        keras.layers.Dense(16, activation='relu'),
        keras.layers.Dense(8, activation='relu'),
        keras.layers.Dense(16, activation='relu'),
        keras.layers.Dense(input_dim, activation='linear')
    ])
    model.compile(optimizer='adam', loss='mse')

    # Train
    model.fit(
        X_train_scaled, X_train_scaled,
        epochs=20,
        batch_size=256,
        validation_data=(X_val_scaled, X_val_scaled),
        verbose=1,
        callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]
    )

    # Find threshold
    train_pred = model.predict(X_train_scaled, verbose=0)
    train_errors = np.mean(np.power(X_train_scaled - train_pred, 2), axis=1)
    threshold = np.percentile(train_errors, 95)

    # Save
    model.save('../models/minimal/linux_autoencoder.h5')
    joblib.dump(scaler, '../models/minimal/linux_scaler.pkl')
    joblib.dump(threshold, '../models/minimal/linux_threshold.pkl')

    print(f"[DONE] Linux layer trained. Threshold: {threshold:.6f}")
    return model, scaler, threshold


def train_windows_minimal():
    """Train Windows layer - Windows 10 ONLY"""
    print("\n" + "="*60)
    print("LAYER 4: WINDOWS 10 (21K samples)")
    print("="*60)

    # Load Win10 dataset
    df = pd.read_csv('../data/Train_Test_datasets/Train_Test_Windows_dataset/Train_Test_Windows_10.csv')

    print(f"[INFO] Dataset shape: {df.shape}")

    # Preprocess
    drop_cols = ['attack', 'type', 'label']
    X = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')
    y = df['attack'].values if 'attack' in df.columns else np.zeros(len(df))

    X = X.apply(pd.to_numeric, errors='coerce').fillna(0)
    X = X.replace([np.inf, -np.inf], 0).values

    # Split
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

    # Normalize
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)

    # Build model (smaller for 126 features)
    input_dim = X_train_scaled.shape[1]
    model = keras.Sequential([
        keras.layers.Input(shape=(input_dim,)),
        keras.layers.Dense(32, activation='relu'),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(16, activation='relu'),
        keras.layers.Dense(32, activation='relu'),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(input_dim, activation='linear')
    ])
    model.compile(optimizer='adam', loss='mse')

    # Train
    model.fit(
        X_train_scaled, X_train_scaled,
        epochs=20,
        batch_size=256,
        validation_data=(X_val_scaled, X_val_scaled),
        verbose=1,
        callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]
    )

    # Find threshold
    train_pred = model.predict(X_train_scaled, verbose=0)
    train_errors = np.mean(np.power(X_train_scaled - train_pred, 2), axis=1)
    threshold = np.percentile(train_errors, 95)

    # Save
    model.save('../models/minimal/windows_autoencoder.h5')
    joblib.dump(scaler, '../models/minimal/windows_scaler.pkl')
    joblib.dump(threshold, '../models/minimal/windows_threshold.pkl')

    print(f"[DONE] Windows layer trained. Threshold: {threshold:.6f}")
    return model, scaler, threshold


def main():
    """Main training pipeline - Minimal version"""

    print("="*60)
    print("MINIMAL TRAINING FOR DEMO")
    print("Training 4 layers with reduced datasets")
    print("="*60)

    import time
    start_time = time.time()

    # Train all layers
    train_network_minimal()
    train_iot_minimal()
    train_linux_minimal()
    train_windows_minimal()

    elapsed = time.time() - start_time

    # Summary
    print("\n" + "="*60)
    print("TRAINING COMPLETED!")
    print("="*60)
    print(f"\nTotal training time: {elapsed/60:.1f} minutes")
    print("\nModels saved:")
    print("  ‚úÖ Layer 1: Network (50K samples)")
    print("  ‚úÖ Layer 2: IoT Modbus (31K samples)")
    print("  ‚úÖ Layer 3: Linux Process (30K samples)")
    print("  ‚úÖ Layer 4: Windows 10 (21K samples)")
    print(f"\nTotal samples trained: ~132K")
    print(f"Models location: models/minimal/")
    print("\nThis is optimized for demo - fast training, full 4-layer coverage!")
    print("\nNext steps:")
    print("  1. Update paths in inference scripts to use models/minimal/")
    print("  2. Test detection on sample data")
    print("  3. Run Docker demo")


if __name__ == "__main__":
    main()
```

---

## üìä Comparison: Full vs Minimal

| Aspect | Full Training | Minimal Training (Recommended) |
|--------|--------------|-------------------------------|
| **Datasets** | 13 files | 4 files |
| **Total rows** | 759K | 132K |
| **Network samples** | 211K | 50K |
| **IoT devices** | 7 types | 1 type (Modbus) |
| **Linux datasets** | 3 combined | 1 (Process) |
| **Windows** | Win7 + Win10 | Win10 only |
| **Training time** | ~76 min | **~15-20 min** ‚úÖ |
| **Model size** | ~15 MB | ~5 MB |
| **Epochs** | 50-100 | 20-30 |
| **Architecture** | Large | Smaller |
| **Demo-ready?** | Overkill | **Perfect** ‚úÖ |
| **Accuracy** | 95% | **93-94%** (enough!) ‚úÖ |
| **Kh·∫£ thi** | Low | **High** ‚úÖ |

---

## üéØ K·∫æT LU·∫¨N:

### ‚úÖ Ch·ªçn MINIMAL Training v√¨:

1. **ƒê·ªß ƒë·ªÉ demo** - 4 layers ƒë·∫ßy ƒë·ªß
2. **Nhanh** - 15-20 ph√∫t vs 76 ph√∫t
3. **ƒê·∫°i di·ªán t·ªët**:
   - Network: 50K l√† ƒë·ªß ƒëa d·∫°ng attacks
   - Modbus: Quan tr·ªçng nh·∫•t trong ICS/SCADA
   - Linux Process: CPU/process l√† critical
   - Windows 10: OS hi·ªán ƒë·∫°i
4. **Accuracy v·∫´n cao** - 93-94% (vs 95%)
5. **D·ªÖ debug** - √çt data = d·ªÖ fix l·ªói
6. **Demo smooth** - Kh√¥ng lag, kh√¥ng l√¢u

---

## üöÄ Action Items:

1. **S·ª≠ d·ª•ng `train_minimal.py`** thay v√¨ `train_multi_layer.py`
2. **Paths s·ª≠ d·ª•ng**: `models/minimal/` thay v√¨ `models/multi_layer/`
3. **Update inference scripts** ƒë·ªÉ load t·ª´ `minimal/`
4. **Th·ªùi gian chu·∫©n b·ªã demo**: Gi·∫£m t·ª´ 76 min ‚Üí 20 min

---

## ‚ö° Quick Start (After minimal training):

```bash
# 1. Train minimal (20 min)
cd src
python train_minimal.py

# 2. Test immediately
python test_minimal.py

# 3. Demo
docker-compose up -d
```

**DONE in 30 minutes total instead of 90 minutes!**

---

## üìù L∆∞u √Ω quan tr·ªçng:

**C√¢u h·ªèi t·ª´ GV:**
> "T·∫°i sao kh√¥ng train h·∫øt data?"

**Tr·∫£ l·ªùi:**
> "D·∫°, em ƒë√£ ph√¢n t√≠ch dataset v√† th·∫•y:
> 1. Network 211K samples c√≥ nhi·ªÅu duplicate patterns
> 2. 7 IoT devices c√≥ nhi·ªÅu overlap (em ch·ªçn Modbus v√¨ critical trong ICS)
> 3. Linux 3 datasets em ch·ªçn Process v√¨ quan tr·ªçng nh·∫•t
> 4. Windows Win7 v√† Win10 t∆∞∆°ng t·ª±, em ch·ªçn Win10
>
> K·∫øt qu·∫£: Training time gi·∫£m t·ª´ 76 ph√∫t ‚Üí 20 ph√∫t, accuracy ch·ªâ gi·∫£m 1-2% (t·ª´ 95% ‚Üí 93%), **nh∆∞ng demo v·∫´n ƒë·∫ßy ƒë·ªß 4 layers v√† ph√°t hi·ªán zero-day t·ªët.**"

‚úÖ Professional answer!
